{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#intiating loggers\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def pred(x: np.ndarray, b0: float, b1: float) -> float:\n",
    "    \"\"\"\n",
    "    Predicts the probability of a binary outcome (class 1) given the input features and coefficients.\n",
    "\n",
    "    Parameters:\n",
    "    x (np.ndarray): The input features as a numpy array.\n",
    "    b0 (float): The intercept of the logistic regression model.\n",
    "    b1 (float): The coefficient of the logistic regression model.\n",
    "\n",
    "    Returns:\n",
    "    float: The probability of class 1.\n",
    "\n",
    "    \"\"\"\n",
    "    val = b0 + b1 * x\n",
    "    return 1 / (1 + np.exp(-val))\n",
    "\n",
    "def l1(b0: float, b1: float, alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the L1 regularization penalty.\n",
    "\n",
    "    Parameters:\n",
    "    b0 (float): The intercept of the logistic regression model.\n",
    "    b1 (float): The coefficient of the logistic regression model.\n",
    "    alpha (float): Regularization strength.\n",
    "\n",
    "    Returns:\n",
    "    float: The L1 regularization penalty value.\n",
    "\n",
    "    \"\"\"\n",
    "    return alpha * (abs(b0) + abs(b1)) / 2\n",
    "\n",
    "def l2(b0: float, b1: float, alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the L2 regularization penalty.\n",
    "\n",
    "    Parameters:\n",
    "    b0 (float): The intercept of the logistic regression model.\n",
    "    b1 (float): The coefficient of the logistic regression model.\n",
    "    alpha (float): Regularization strength.\n",
    "\n",
    "    Returns:\n",
    "    float: The L2 regularization penalty value.\n",
    "\n",
    "    \"\"\"\n",
    "    return alpha * (b0**2 + b1**2) / 2\n",
    "\n",
    "def elasticnet(b0: float, b1: float, alpha: float, l1_ratio: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the elastic net regularization penalty.\n",
    "\n",
    "    Parameters:\n",
    "    b0 (float): The intercept of the logistic regression model.\n",
    "    b1 (float): The coefficient of the logistic regression model.\n",
    "    alpha (float): Regularization strength.\n",
    "    l1_ratio (float): The mixing parameter for the L1 and L2 penalties.\n",
    "\n",
    "    Returns:\n",
    "    float: The elastic net regularization penalty value.\n",
    "\n",
    "    \"\"\"\n",
    "    return l1_ratio * l1(b0, b1, alpha) + (1 - l1_ratio) * l2(b0, b1, alpha)\n",
    "\n",
    "def comp_class_weights(y_train: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes class weights to address class imbalance.\n",
    "\n",
    "    Parameters:\n",
    "    y_train (np.ndarray): The target variable as a numpy array containing binary labels (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: An array of class weights.\n",
    "\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y_train, return_counts=True)\n",
    "    return len(y_train) / (2 * counts)\n",
    "\n",
    "#LR function\n",
    "def LR(x: np.ndarray, y: np.ndarray, alpha = 1, debug= False, penalty: function =l1, l1_ratio=0.5, class_weights: tuple= None):\n",
    "    \"\"\"\n",
    "    Logistic Regression with Regularization (LR)\n",
    "\n",
    "    This function performs Logistic regression with regularization (L1, L2, or elastic net) to fit a model to the input data.\n",
    "    \n",
    "    Parameters:\n",
    "    x (np.ndarray): The input features as a numpy array.\n",
    "    y (np.ndarray): The target variable as a numpy array.\n",
    "    alpha (float, optional): Regularization strength (default=1).\n",
    "    debug (bool, optional): If True, enables debugging mode (default=False).\n",
    "    penalty (function, optional): Regularization penalty function. Supported values are l1, l2, or elasticnet (default=l1).\n",
    "    l1_ratio (float, optional): The mixing parameter for elastic net when penalty is set to elasticnet (default=0.5).\n",
    "    class_weights (tuple, optional): Tuple containing class weights to address class imbalance. Set to None by default.\n",
    "\n",
    "    Returns:\n",
    "    b0 (float): Intercept of the fitted model.\n",
    "    b1 (float): Coefficient of the fitted model.\n",
    "\n",
    "    Note:\n",
    "    The class_weights parameter is a tuple containing the weights for the two classes in the dataset.\n",
    "      If set to None, the class weights are automatically calculated and used. If set to \"balanced\", \n",
    "      the class weights are automatically calculated and used, but the weights \n",
    "      are assigned inversely proportional to the class frequencies in the input data.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If l1_ratio is set and penalty is not set to elasticnet.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #debug statement\n",
    "    if debug:\n",
    "        logger.info(f\"Input: x = {x}, y = {y}, alpha = {alpha}, penalty = {penalty}, l1_ratio = {l1_ratio}\")\n",
    "\n",
    "    #assigning class weights\n",
    "    if class_weights == \"balanced\":\n",
    "        class_weights = comp_class_weights(y_train)\n",
    "    else:\n",
    "        class_weights = (0,0)\n",
    "\n",
    "    #checking l1_ratio usage\n",
    "    if (penalty in [l1,l2]) and l1_ratio != 0.5:\n",
    "        raise ValueError(\"l1_ratio can only be set when penalty is set to 'elasticnet' \")\n",
    "\n",
    "\n",
    "    b0, b1 = class_weights\n",
    "    l = 0.001\n",
    "    iters = 1000\n",
    "\n",
    "    for i in range(iters):\n",
    "        \n",
    "        #debug statement\n",
    "        if debug:\n",
    "            logger.info(f\"Iteration {i}: b0 = {b0}, b1 = {b1}\")\n",
    "\n",
    "        y_pred = pred(x, b0, b1)\n",
    "\n",
    "        #change of weights when penalty is set to l1\n",
    "        if penalty==l1:\n",
    "            \n",
    "            db0 = -2*np.mean((y-y_pred)*y_pred*(1-y_pred)) + l1(b0,b1,alpha)\n",
    "            db1 = -2*np.mean((y-y_pred)*y_pred*(1-y_pred)*x) + l1(b0,b1,alpha)\n",
    "\n",
    "        #change of weights when penalty is set to l2\n",
    "        elif penalty==l2:\n",
    "            db0 = -2*np.mean((y-y_pred)*y_pred*(1-y_pred)) + l2(b0,b1,1)\n",
    "            db1 = -2*np.mean((y-y_pred)*y_pred*(1-y_pred)*x) + l2(b0,b1,1)\n",
    "\n",
    "        #change of weights when penalty is set to elasticnet\n",
    "        elif penalty==elasticnet:\n",
    "            db0 = -2*np.mean((y-y_pred)*y_pred*(1-y_pred)) + elasticnet(b0,b1,1,l1_ratio)\n",
    "            db1 = -2*np.mean((y-y_pred)*y_pred*(1-y_pred)*x) + elasticnet(b0,b1,1,l1_ratio)\n",
    "\n",
    "        b0 = b0-l*db0\n",
    "        b1 = b1-l*db1\n",
    "\n",
    "    return b0, b1\n",
    "\n",
    "#convert the y_pred values to binary output\n",
    "def bin(x, b0, b1):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts the predicted probabilities to binary output.\n",
    "\n",
    "    Parameters:\n",
    "    x (np.ndarray): The input features as a numpy array.\n",
    "    b0 (float): The intercept of the logistic regression model.\n",
    "    b1 (float): The coefficient of the logistic regression model.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: An array of binary output values (0 or 1).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = pred(x, b0, b1)\n",
    "    return [1 if i > 0.5 else 0 for i in y_pred]\n",
    "\n",
    "\n",
    "\n",
    "#loading dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "#test, train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.25, random_state=42)\n",
    "\n",
    "#normalizing the data for better outputs\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#calling the LR function and printing the optimal output weights\n",
    "b0, b1 = LR(X_train[:, 0], y_train, alpha=0.8)\n",
    "print(\"b0:\", b0, \"b1:\", b1)\n",
    "\n",
    "#calculating the accuracy\n",
    "y_pred = bin(X_test[:, 0], b0, b1)\n",
    "print(\"Accuracy:\", np.mean(y_pred == y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
